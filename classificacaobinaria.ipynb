{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ollcesar/projeto-inteligencia-artificial/blob/main/classificacaobinaria.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yf0FpJ35Lf-Z"
      },
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torchvision import datasets, transforms\n",
        "import zipfile\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1vw_qANCnRx"
      },
      "source": [
        "torch.manual_seed(123)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classificador = nn.Sequential(\n",
        "    nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3),\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm2d(num_features=32),\n",
        "    nn.MaxPool2d(kernel_size=2),\n",
        "    nn.Conv2d(32, 32, 3),\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm2d(32),\n",
        "    nn.MaxPool2d(2),\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(in_features=14*14*32, out_features=128),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.2),\n",
        "    nn.Linear(128, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.2),\n",
        "    nn.Linear(128, 4)\n",
        ")\n"
      ],
      "metadata": {
        "id": "w9RNEbYpyMHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TF0aWpgKhd1U"
      },
      "source": [
        "criterion = nn.BCELoss()\n",
        "optimizer = optim.Adam(classificador.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtFmsx5CiFiF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6e0c9d7-619f-4fc9-aa6c-40146c7abd76"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrFGMM3Qiboh"
      },
      "source": [
        "path = '/content/drive/MyDrive/dataset.zip'\n",
        "zip_object = zipfile.ZipFile(file = path, mode = 'r')\n",
        "zip_object.extractall('./')\n",
        "zip_object.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJlU2mkBi82r"
      },
      "source": [
        "data_dir_train = '/content/dataset/training_set'\n",
        "data_dir_test = '/content/dataset/test_set'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oe0zfyIujF4r"
      },
      "source": [
        "transform_train = transforms.Compose(\n",
        "    [\n",
        "     transforms.Resize([64, 64]),\n",
        "     transforms.RandomHorizontalFlip(),\n",
        "     transforms.RandomAffine(degrees=7, translate=(0, 0.07), shear=0.2, scale=(1, 1.2)),\n",
        "     transforms.ToTensor()\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrfHFgirjyiP"
      },
      "source": [
        "transform_test = transforms.Compose(\n",
        "    [\n",
        "     transforms.Resize([64, 64]),\n",
        "     transforms.ToTensor()\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkXg89sDkCK4"
      },
      "source": [
        "train_dataset = datasets.ImageFolder(data_dir_train, transform=transform_train)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size = 32, shuffle=True)\n",
        "test_dataset = datasets.ImageFolder(data_dir_test, transform=transform_test)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size = 32, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuB-jEM_T8_I"
      },
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "device"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAIlw7fR8QtS"
      },
      "source": [
        "classificador.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(loader, epoch):\n",
        "    running_loss = 0.0\n",
        "    running_accuracy = 0.0\n",
        "    \n",
        "    for i, data in enumerate(loader):\n",
        "        inputs, labels = data\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()        \n",
        "        outputs = classificador(inputs)\n",
        "        \n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        accuracy = torch.mean((predicted == labels).float())\n",
        "        running_accuracy += accuracy\n",
        "\n",
        "        print('\\rÉPOCA {:3d} - Loop {:3d} de {:3d}: perda {:.5f} - precisão {:.5f}'.format(epoch + 1, i + 1, len(loader), loss.item(), accuracy.item()), end='\\r')\n",
        "    \n",
        "    print('\\rÉPOCA {:3d} FINALIZADA: perda {:.5f} - precisão {:.5f}'.format(epoch + 1, running_loss / len(loader), running_accuracy / len(loader)))"
      ],
      "metadata": {
        "id": "VkKzgDUdw38H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEKi9zzYEmIU"
      },
      "source": [
        "for epoch in range(10):\n",
        "    print('TREINAMENTO DO MODELO')\n",
        "    training_loop(train_loader, epoch)\n",
        "    classificador.eval()\n",
        "    print('VALIDAÇÃO DO MODELO')\n",
        "    training_loop(test_loader, epoch)\n",
        "    classificador.train()\n",
        "    print('-----------------------------------------')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMRlArb6oqnk"
      },
      "source": [
        "def classificar_imagem(fname):\n",
        "  from PIL import Image\n",
        "  import matplotlib.pyplot as plt\n",
        "  imagem_teste = Image.open(data_dir_test + '/' + fname)\n",
        "  plt.imshow(imagem_teste)\n",
        "\n",
        "  import numpy as np\n",
        "  imagem_teste = imagem_teste.resize((64, 64))\n",
        "  imagem_teste = np.array(imagem_teste.getdata()).reshape(*imagem_teste.size, 3)\n",
        "  imagem_teste = imagem_teste / 255\n",
        "  imagem_teste = imagem_teste.transpose(2, 0, 1)\n",
        "  imagem_teste = torch.tensor(imagem_teste, dtype=torch.float).view(-1, *imagem_teste.shape)\n",
        "\n",
        "  classificador.eval()\n",
        "  imagem_teste = imagem_teste.to(device)\n",
        "  output = classificador.forward(imagem_teste)\n",
        "  if output > 0.5:\n",
        "    output = 1\n",
        "  else:\n",
        "    output = 0\n",
        "  print('Previsão: ', output)\n",
        "\n",
        "  idx_to_class = {value: key for key, value in test_dataset.class_to_idx.items()}\n",
        "\n",
        "  return idx_to_class[output]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dUxZY0I1qrNW"
      },
      "source": [
        "imagem = '/PLM/0001-1000/PLM_00435.jpg'\n",
        "classificar_imagem(imagem)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "from torchvision import datasets, transforms\n",
        "import zipfile\n",
        "\n",
        "torch.manual_seed(123)\n",
        "\n",
        "classificador = nn.Sequential(\n",
        "    nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3),\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm2d(num_features=32),\n",
        "    nn.MaxPool2d(kernel_size=2),\n",
        "    nn.Conv2d(32, 32, 3),\n",
        "    nn.ReLU(),\n",
        "    nn.BatchNorm2d(32),\n",
        "    nn.MaxPool2d(2),\n",
        "    nn.Flatten(),\n",
        "    nn.Linear(in_features=14*14*32, out_features=128),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.2),\n",
        "    nn.Linear(128, 128),\n",
        "    nn.ReLU(),\n",
        "    nn.Dropout(0.2),\n",
        "    nn.Linear(128, 4)\n",
        ")\n"
      ],
      "metadata": {
        "id": "rh5FeePl1vVc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}